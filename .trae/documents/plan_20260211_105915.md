# 实现计划：AI助手RAG系统

## 1. 知识库基础设施

* **目录结构**：在 `src/main/resources/docs/knowledge/`下为每个助手创建独立的目录：
  * `/code`、`/travel`、`/essay`、`/material`、`/medical`、`/college`。
* **文档生成**：为每个助手创建5个示例Markdown文件（共30个文件）。
  * **格式**：YAML Front Matter（标题、版本、标签等）+ Markdown 内容。
  * **内容**：领域特定知识（例如，为代码助手创建“Java Stream API指南”，为旅行助手创建“巴黎旅行指南”）。

## 2. 高级RAG管道实现

* **`RagService`**：创建一个中心化服务来处理文档摄取。
  * **异步处理**：使用 `@Async`实现非阻塞的知识库初始化。
  * **缓存**：实现基于校验和或时间戳的缓存机制，以跳过未更改文件的重复摄取（针对InMemory存储进行模拟）。
* **文档处理**：
  * **分割器**：按要求使用 `DocumentSplitters.recursive(1000, 200)`。
  * **元数据转换器**：实现 `AdvancedMetadataTransformer`以：
    * 解析YAML front matter。
    * 提取标题（Sections）。
    * 检测代码块和实体（基于正则表达式）。
* **向量存储**：
  * 配置6个独立的 `InMemoryEmbeddingStore`实例（每个助手一个），以确保数据隔离。
  * 将存储持久化到本地JSON文件，避免每次重启时重新构建（如果可行，否则在启动时重新构建）。

## 3. 检索与重排序

* **检索**：为每个助手配置 `EmbeddingStoreContentRetriever`。
  * **混合搜索**：由于 `InMemoryEmbeddingStore`仅支持稠密向量检索，我们将通过设置高阈值来优化稠密向量搜索。（真正的BM25需要Lucene/Elasticsearch，这超出了此轻量级设置的范围，但我们会构建可扩展的管道结构）。
* **重排序**：实现 `ReRankingContentRetriever`。
  * 使用一个 `ScoringModel`（将实现一个基础模型，或如果没有专用的Rerank模型API，则适配现有的ChatModel）。*注意：我们将为管道配置`top-k=5`。*

## 4. 集成

* **`RagConfig`**：定义6个Retriever Bean（`codeRetriever`、`travelRetriever`等）。
* **`AiCodeHelperServiceFactory`**：
  * 将特定的Retriever注入到每个 `AiService`构建器中（目前仅代码助手有一个；将扩展到所有6个助手）。

## 5. 验证

* 验证每个助手是否能够基于其特定知识库文件回答问题。
* 检查启动日志中的异步摄取进度。

## 分步执行

1. **创建文件**：生成目录结构和Markdown文件。
2. **代码 - 转换器**：实现 `AdvancedMetadataTransformer`。
3. **代码 - 配置**：更新 `RagConfig`以创建多个存储/检索器。
4. **代码 - 工厂**：更新 `AiCodeHelperServiceFactory`以绑定检索器。
5. **测试**：启动后端并验证RAG响应。

